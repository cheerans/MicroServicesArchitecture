Autoscaling
-----------

you could run via yaml like below

#https://docs.docker.com/get-started/kube-deploy/
the yaml file will deaclre deployment, replica, expose as service, expose ports to external ports etc
kubectl apply -f bb.yaml
kubectl delete -f bb.yaml

#https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226

./kubect run hello-nginx --image=scheeran/nginx --port=80
o/p: deployment "hello-nginx" created

kubectl get pods

kubectl expose deployment hello-nginx --type=NodePort
o/p: service "hello-nginx" exposed

kubectl get services

-- manual scaling
kubectl scale --replicas=3 deployment/hello-nginx
o/p: deployment "hello-nginx" scaled

kubectl autoscale deployment/hello-nginx --min=2 --max=5 --cpu-percent=80

https://kubernetes.io/blog/2016/07/autoscaling-in-kubernetes/
Setting Up Autoscaling on GCE
--------------------------------
The following instructions apply to GCE. For GKE please check the autoscaling section in cluster operations manual available here.

Before we begin, we need to have an active GCE project with Google Cloud Monitoring, Google Cloud Logging and Stackdriver enabled. For more information on project creation, please read our Getting Started Guide. We also need to download a recent version of Kubernetes project (version v1.3.0 or later).

First, we set up a cluster with Cluster Autoscaler turned on. The number of nodes in the cluster will start at 2, and autoscale up to a maximum of 5. To implement this, weâ€™ll export the following environment variables:

export NUM\_NODES=2

export KUBE\_AUTOSCALER\_MIN\_NODES=2

export KUBE\_AUTOSCALER\_MAX\_NODES=5

export KUBE\_ENABLE\_CLUSTER\_AUTOSCALER=true
and start the cluster by running:

./cluster/kube-up.sh

kubectl autoscale deployment <Application Name> --cpu-percent = 50 --min = 1 --max = 10
